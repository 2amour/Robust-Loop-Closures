/*
 * Copyright 2014 Google Inc. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.kitware.tangoproject.paraviewtangorecorder;

import android.content.Context;
import android.content.Intent;
import android.content.SharedPreferences;
import android.graphics.Bitmap;
import android.graphics.Point;
import android.net.Uri;
import android.opengl.GLES20;
import android.opengl.GLSurfaceView;
import android.opengl.Matrix;
import android.opengl.GLES11Ext;
import android.os.AsyncTask;
import android.os.Environment;
import android.widget.Toast;

// Need OpenGL ES 3.0 for RGBA8 renderbuffer.
import static android.opengl.GLES30.*;

import javax.microedition.khronos.egl.EGLConfig;
import javax.microedition.khronos.opengles.GL10;

import com.google.atap.tangoservice.Tango;
import com.google.atap.tangoservice.TangoCameraIntrinsics;
import com.projecttango.tangoutils.Renderer;
import com.projecttango.tangoutils.renderables.CameraFrustum;
import com.projecttango.tangoutils.renderables.CameraFrustumAndAxis;
import com.projecttango.tangoutils.renderables.Grid;
import com.projecttango.tangoutils.renderables.PointCloud;

import java.io.File;
import java.io.FileOutputStream;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.IntBuffer;

/**
 * OpenGL rendering class for the Motion Tracking API sample. This class
 * managers the objects visible in the OpenGL view which are the
 * {@link CameraFrustum}, {@link PointCloud} and the {@link Grid}. These objects
 * are implemented in the TangoUtils library in the package
 * {@link com.projecttango.tangoutils.renderables}.
 *
 * This class receives {@link TangoPose} data from the {@link MotionTracking}
 * class and updates the model and view matrices of the {@link Renderable}
 * objects appropriately. It also handles the user-selected camera view, which
 * can be 1st person, 3rd person, or top-down.
 *
 */
public class CameraRenderer extends Renderer implements GLSurfaceView.Renderer {

    private PointCloud mPointCloud;
    private Grid mGrid;
    private CameraFrustumAndAxis mCameraFrustumAndAxis;
    private int mMaxDepthPoints;
    private boolean mIsValid = false;

    private PointCloudActivity activity_;
    int videoProgram_;
    int videoVertexAttribute_;
    int videoVertexBuffer_;
    int videoTextureName_;

    int offscreenBuffer_;
    Point offscreenSize_;

    private boolean saveBitmap = true;

    public CameraRenderer(int maxDepthPoints, PointCloudActivity activity) {
        mMaxDepthPoints = maxDepthPoints;
        activity_ = activity;
    }

    @Override
    public void onSurfaceCreated(GL10 gl, EGLConfig config) {

        GLES20.glClearColor(1f, 1f, 1f, 1.0f);
        GLES20.glEnable(GLES20.GL_DEPTH_TEST);
        mPointCloud = new PointCloud(mMaxDepthPoints);
        mGrid = new Grid();
        mCameraFrustumAndAxis = new CameraFrustumAndAxis();
        Matrix.setIdentityM(mViewMatrix, 0);
        Matrix.setLookAtM(mViewMatrix, 0, 5f, 5f, 5f, 0f, 0f, 0f, 0f, 1f, 0f);
        mCameraFrustumAndAxis.setModelMatrix(getModelMatCalculator().getModelMatrix());
        mIsValid = true;

        // Get the camera frame dimensions.
        offscreenSize_ = activity_.getCameraFrameSize(TangoCameraIntrinsics.TANGO_CAMERA_COLOR);

        // Create framebuffer
        IntBuffer framebufferName = IntBuffer.allocate(1);
        glGenFramebuffers(1, framebufferName);
        glBindFramebuffer(GL_RENDERBUFFER, framebufferName.get(0));

        // Attach renderbuffer
        IntBuffer renderbufferName = IntBuffer.allocate(1);
        glGenRenderbuffers(1, renderbufferName);
        glBindRenderbuffer(GL_RENDERBUFFER, renderbufferName.get(0));
        glRenderbufferStorage(GL_RENDERBUFFER, GL_RGBA8, offscreenSize_.x, offscreenSize_.y);
        glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_RENDERBUFFER, renderbufferName.get(0));

        // Create the video texture.
        IntBuffer textureNames = IntBuffer.allocate(1);
        glGenTextures(1, textureNames);

        // "Bind" the newly created texture : all future texture functions will modify this texture
        glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, videoTextureName_);
        glTexParameteri(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
        glTexParameteri(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GL_TEXTURE_MAG_FILTER, GL_NEAREST);

        videoTextureName_ = textureNames.get(0);

        // Connect the texture to Tango.
        activity_.attachTexture(TangoCameraIntrinsics.TANGO_CAMERA_COLOR, videoTextureName_);

        // unbind frame buffer
        glBindRenderbuffer(GL_RENDERBUFFER, 0);
        glBindFramebuffer(GL_FRAMEBUFFER, 0);
        glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, 0);

    }

    @Override
    public void onSurfaceChanged(GL10 gl, int width, int height) {
        GLES20.glViewport(0, 0, width, height);
        mCameraAspect = (float) width / height;
        Matrix.perspectiveM(mProjectionMatrix, 0, CAMERA_FOV, mCameraAspect, CAMERA_NEAR,
                CAMERA_FAR);
    }

    @Override
    public void onDrawFrame(GL10 gl) {

        if(saveBitmap)
        {
            saveBitmap();
        }

            GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);
            mGrid.draw(mViewMatrix, mProjectionMatrix);
            synchronized (PointCloudActivity.depthLock) {
                mPointCloud.draw(mViewMatrix, mProjectionMatrix);
            }
            synchronized (PointCloudActivity.poseLock) {
                mCameraFrustumAndAxis.draw(mViewMatrix, mProjectionMatrix);
            }
    }

    public PointCloud getPointCloud() {
        return mPointCloud;
    }

    public boolean isValid(){
        return mIsValid;
    }

    public void saveBitmap()
    {
        saveBitmap = true;

        activity_.updateTexture(TangoCameraIntrinsics.TANGO_CAMERA_COLOR);

        // Get the camera frame dimensions.
        offscreenSize_ = activity_.getCameraFrameSize(TangoCameraIntrinsics.TANGO_CAMERA_COLOR);

        // Switch to the offscreen buffer.
        GLES20.glBindFramebuffer(GL_FRAMEBUFFER, offscreenBuffer_);
        glViewport(0, 0, offscreenSize_.x, offscreenSize_.y);

        GLES20.glFramebufferTexture2D(GLES20.GL_FRAMEBUFFER, GLES20.GL_COLOR_ATTACHMENT0, GLES20.GL_TEXTURE_2D, videoTextureName_, 0);

        // Read offscreen buffer.
        IntBuffer intBuffer = ByteBuffer.allocateDirect(offscreenSize_.x * offscreenSize_.y * 4)
                .order(ByteOrder.nativeOrder())
                .asIntBuffer();
        GLES20.glReadPixels(0, 0, offscreenSize_.x, offscreenSize_.y, GL_RGBA, GL_UNSIGNED_BYTE, intBuffer.rewind());

        // Convert to an array for Bitmap.createBitmap().
        int[] pixelsBuffer = new int[intBuffer.capacity()];
        intBuffer.rewind();
        intBuffer.get(pixelsBuffer);

        int screenshotSize = offscreenSize_.x * offscreenSize_.y;

        for (int i = 0; i < screenshotSize; ++i) {
            // The alpha and green channels' positions are preserved while the red and blue are swapped
            pixelsBuffer[i] = ((pixelsBuffer[i] & 0xff00ff00)) | ((pixelsBuffer[i] & 0x000000ff) << 16) | ((pixelsBuffer[i] & 0x00ff0000) >> 16);
        }

        Bitmap bitmap = Bitmap.createBitmap(offscreenSize_.x, offscreenSize_.y, Bitmap.Config.ARGB_8888);
        bitmap.setPixels(pixelsBuffer, screenshotSize-offscreenSize_.x, -offscreenSize_.x, 0, 0, offscreenSize_.x, offscreenSize_.y);

        try {
            // Create/access a pictures subdirectory.
            File directory = new File(
                    Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_PICTURES),
                    "Tango Captures");
            if (!directory.mkdirs() && !directory.isDirectory()) {
                Toast.makeText(
                        activity_,
                        "Could not access save directory",
                        Toast.LENGTH_SHORT).show();
                return;
            }

            // Get the current capture index to construct a unique filename.
            SharedPreferences prefs = activity_.getPreferences(Context.MODE_PRIVATE);
            int index = prefs.getInt("index", 0);
            SharedPreferences.Editor prefsEditor = prefs.edit();
            prefsEditor.putInt("index", index + 1);
            prefsEditor.apply();

            // Create the capture file.
            File file = new File(directory, String.format("GoogleTango_%05d.png", index));
            FileOutputStream fileOutputStream = new FileOutputStream(file);

            // Bitmap conveniently provides file output.
            //Bitmap bitmap = Bitmap.createBitmap(pixels, offscreenSize_.x, offscreenSize_.y, Bitmap.Config.ARGB_8888);
            bitmap.compress(Bitmap.CompressFormat.PNG, 90, fileOutputStream);
            fileOutputStream.close();

            // Make the new file visible to other apps.
            activity_.sendBroadcast(new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE, Uri.fromFile(file)));
        }
        catch (Exception ex){};

        // unbind frame buffer
        glBindRenderbuffer(GL_RENDERBUFFER, 0);
        glBindFramebuffer(GL_FRAMEBUFFER, 0);
        glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, 0);
    }

    public void startCamera()
    {
        // Background task for writing to file
        class SendCommandTask extends AsyncTask<Void, Void, Boolean> {
            /** The system calls this to perform work in a worker thread and
             * delivers it the parameters given to AsyncTask.execute() */
            @Override
            protected Boolean doInBackground(Void... params) {

                            /*
                                // Clear the target (optional)
                                glClearColor(1.0f, 1.0f, 1.0f, 1.0f);
                                glClear(GL_COLOR_BUFFER_BIT);



                            glDeleteRenderbuffers(1, renderbufferName);
                            glDeleteFramebuffers(1, framebufferName);*/

                return true;
            }

            /** The system calls this to perform work in the UI thread and delivers
             * the result from doInBackground() */
            @Override
            protected void onPostExecute(Boolean done) {

            }
        }
        new SendCommandTask().execute();

    }
}
